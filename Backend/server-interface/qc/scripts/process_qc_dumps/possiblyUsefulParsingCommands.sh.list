# Copyright 2016 Matthias Petursson
# Apache 2.0
#
# Some possibly useful commands while parsing the QC dumps.

# get rid of duplicates in qc_dump_combined file by sorting on .wav name
# removes header (you'll probably want to add that manually)
tail -n +2 qc_dump_combined.txt | sort -u -k 15

# calculate average accuracy
cat qc_dump_combined.txt | awk 'BEGIN{tot=0;}{tot+=$3;}END{print tot / NR}'

# remove all lines in qc_dump with tokens with specific promptlabels ('en')
mysql -u root -D "recordings_master" -e "select id from token where promptLabel='en';"  | \
grep -v -f - qc_dump_combined.txt > qc_dump_combined_no_en.txt

# grab lowest scoring 300
tail -n +2 qc_dump_combined_no_en.txt | shuf | awk 'BEGIN{tot=0;} {if ($3 < 0.2 && $12 != "true" && tot < 300) {print; tot+=1;}}' > worst300.txt

# grab highest scoring 300
tail -n +2 qc_dump_combined_no_en.txt | shuf | awk 'BEGIN{tot=0;} {if ($3 > 0.8 && tot < 300) {print; tot+=1;}}' > best300.txt

# grab middle scoring 300
tail -n +2 qc_dump_combined_no_en.txt | shuf | awk 'BEGIN{tot=0;} {if ($3 > 0.3 && $3 < 0.7 && tot < 300) {print; tot+=1;}}' > mid300.txt

# grab and wrap the recordings mentioned in a file to a tarball
name=best300
mkdir "$name"
cut -f 15 "$name".txt | \
while read line; do 
    cp $(find /data/eyra/recordings -name "$line") "$name"/"$line" || echo "Failed to copy: $line"
    sleep 0.2
done
tar -czf "$name".tgz "$name" "$name".txt
rm -rf "$name"

