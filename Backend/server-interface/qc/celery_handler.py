from celery import Celery
from . import celery_config

# this code is generated by setupActiveModules.py script
# @@CELERYQCBASETASKIMPORTS
from .modules.TestModule import TestTask
# @@/CELERYQCBASETASKIMPORTS

host = celery_config.const['host']
port = celery_config.const['port']
broker_db = celery_config.const['broker_db']
backend_db = celery_config.const['backend_db']

broker = 'redis://{}:{}/{}'.format(host, port, broker_db)

celery = Celery(broker=broker)
celery.conf.update(
    CELERY_RESULT_BACKEND='redis://{}:{}/{}'.format(host, port, backend_db)
)

# this code is used as template for the setupActiveModules.py script
# should be commented out here
# @@CELERYQCPROCESSTEMPLATE
# @celery.task(base=TestTask, name='celery.qcProcSessionTestModule')
# def qcProcSessionTestModule(name, sessionId, slistIdx=0, batchSize=5):
#     """
#     Goes through the sessionList, containing a list of all current
#     recordings of this session, in the backend continuing from
#     slistIdx. 

#     Performs qcProcSessionTestModule.processBatch which does the processing, 
#     it must take exactly 3 arguments, the first being the name used for identification
#     in the redis datastore (e.g. 'report/name/sessionId'), and
#     the second is sessionId, third is a list of indices of recordings to process. 
#     processBatch is responsible for putting the results on the correct format in the
#     report in the redis datastore. Obviously, processBatch needs to be a
#     synchronous function.

#     Only processes batchSize recs at a time, until calling itself recursively
#     with the updated slistIdx (and by that placing itself at the back
#     of the celery queue), look at instagram, that's how they do it xD
#     """
#     print('goodbye cruel world')
     
#     result = qcProcSessionTestModule.processBatch(name, sessionId, list(range(slistIdx, slistIdx+batchSize)))
#     if result:
#        qcProcSessionTestModule.apply_async(
#            args=[name, sessionId, slistIdx+batchSize, batchSize])
# @@/CELERYQCPROCESSTEMPLATE

# this code is generated by setupActiveModules.py script
# @@CELERYQCPROCESSTASKS
@celery.task(base=TestTask, name='celery.qcProcSessionTestModule')
def qcProcSessionTestModule(name, sessionId, slistIdx=0, batchSize=5):
    """
    Goes through the sessionList, containing a list of all current
    recordings of this session, in the backend continuing from
    slistIdx. 

    Performs qcProcSessionTestModule.processBatch which does the processing, 
    it must take exactly 3 arguments, the first being the name used for identification
    in the redis datastore (e.g. 'report/name/sessionId'), and
    the second is sessionId, third is a list of indices of recordings to process. 
    processBatch is responsible for putting the results on the correct format in the
    report in the redis datastore. Obviously, processBatch needs to be a
    synchronous function.

    Only processes batchSize recs at a time, until calling itself recursively
    with the updated slistIdx (and by that placing itself at the back
    of the celery queue), look at instagram, that's how they do it xD
    """
    print('goodbye cruel world')
     
    result = qcProcSessionTestModule.processBatch(name, sessionId, list(range(slistIdx, slistIdx+batchSize)))
    if result:
       qcProcSessionTestModule.apply_async(
           args=[name, sessionId, slistIdx+batchSize, batchSize])


# @@/CELERYQCPROCESSTASKS