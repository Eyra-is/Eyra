from celery import Celery
from . import celery_config

# this code is generated by script
# @@CELERYQCBASETASKIMPORTS
from .modules.TestModule import TestTask
from .modules.DummyModule import DummyTask
# @@/CELERYQCBASETASKIMPORTS

host = celery_config.const['host']
port = celery_config.const['port']
broker_db = celery_config.const['broker_db']
backend_db = celery_config.const['backend_db']

broker = 'redis://{}:{}/{}'.format(host, port, broker_db)

celery = Celery(broker=broker)
celery.conf.update(
    CELERY_RESULT_BACKEND='redis://{}:{}/{}'.format(host, port, backend_db)
)

# this code is generated by script
# @@CELERYQCPROCESSTASKS
@celery.task(base=TestTask, name='celery.qcProcSessionTestModule')
def qcProcSessionTestModule(name, sessionId, slistIdx=0, batchSize=5):
    """
    Goes through the sessionList, containing a list of all current
    recordings of this session, in the backend continuing from
    slistIdx. 

    Performs processFn which is a function pointer to the function
    which does the processing, processFn must take exactly 2 arguments
    the first is sessionId, second is a list of indices of recordings to process. 
    processFn is responsible for putting the results on the correct format in the
    report in the redis datastore. Obviously, processFn needs to be a
    synchronous function.

    Only processes batchSize recs at a time, until calling itself recursively
    with the updated slistIdx (and by that placing itself at the back
    of the celery queue), look at instagram, that's how they do it xD
    """
    print('goodbye cruel world')

    result = qcProcSessionTestModule.processBatch(name, sessionId, list(range(slistIdx, slistIdx+batchSize)))
    if result:
       qcProcSessionTestModule.apply_async(
           args=[name, sessionId, slistIdx+batchSize, batchSize])

@celery.task(base=DummyTask, name='celery.qcProcSessionDummyModule')
def qcProcSessionDummyModule(name, sessionId, slistIdx=0, batchSize=5):
    """
    Goes through the sessionList, containing a list of all current
    recordings of this session, in the backend continuing from
    slistIdx. 

    Performs processFn which is a function pointer to the function
    which does the processing, processFn must take exactly 2 arguments
    the first is sessionId, second is a list of indices of recordings to process. 
    processFn is responsible for putting the results on the correct format in the
    report in the redis datastore. Obviously, processFn needs to be a
    synchronous function.

    Only processes batchSize recs at a time, until calling itself recursively
    with the updated slistIdx (and by that placing itself at the back
    of the celery queue), look at instagram, that's how they do it xD
    """
    print('goodbye cruel world')

    result = qcProcSessionDummyModule.processBatch(name, sessionId, list(range(slistIdx, slistIdx+batchSize)))
    if result:
       qcProcSessionDummyModule.apply_async(
           args=[name, sessionId, slistIdx+batchSize, batchSize])
# @@/CELERYQCPROCESSTASKS